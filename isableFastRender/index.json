[{"authors":null,"categories":null,"content":"Copyright Nina Tahmasebi. All rights reserved.\n","date":1541977200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541977200,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"//localhost:1313/privacy/","publishdate":"2018-11-12T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":"Copyright Nina Tahmasebi. All rights reserved.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":null,"categories":null,"content":"Today, we lack computational tools for studying lexical and semantic changes at a large scale. Current methods are limited and require huge amounts of text. Studies on semantic change capture only main changes of a single word and offer no possibility to capture the interplay of change in a semantic field.\nIn this project, we aim to find automatic, corpus-based methods for detecting semantic change and lexical replacement for Swedish and English. We will investigate the fundamental questions of how, when, and why languages change to allow us to quantify language change and shift lexical typological research from small case studies done on limited data sets to larger scales and over wider time spans using various media types and sources.\nThe results of the project will advance research in NLP and semantics and have practical benefits for researchers in other fields; We aim to facilitate empirical study of language changes themselves, highlight changes for the public to avoid wrongful interpretations and account for language change in large-scale text mining applications such as information extraction and information retrieval. The results will also benefit the public as they access and interpret historical text as well as researchers that wish to track concepts over time without manually finding and accounting for language change.\nProject pages\n","date":1541977200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541977200,"objectID":"0cb6e986b304b626dab101a172094a1e","permalink":"//localhost:1313/project/languagechange/","publishdate":"2018-11-12T00:00:00+01:00","relpermalink":"/project/languagechange/","section":"project","summary":"Computational detection of lexical and semantic change from diachronic texts.","tags":["Data Science","Language Change Detection"],"title":"Towards Automatic Language Change Detection","type":"project"},{"authors":["Adam Jatowt","Ricardo Campos","Sourav S Bhowmick","Nina Tahmasebi","Antoine Doucet"],"categories":null,"content":"","date":1540159200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540159200,"objectID":"edc870c8d20c774112b10c2453fa15da","permalink":"//localhost:1313/publication/2018-cikm2018/","publishdate":"2018-10-22T00:00:00+02:00","relpermalink":"/publication/2018-cikm2018/","section":"publication","summary":"Human language constantly evolves due to the changing world and the need for easier forms of expression and communication. Our knowledge of language evolution is however still fragmentary despite significant interest of both researchers as well as wider public in the evolution of language. In this paper, we present an interactive framework that permits users study the evolution of words and concepts. The system we propose offers a rich online interface allowing arbitrary queries and complex analytics over large scale historical textual data, letting users investigate changes in meaning, context and word relationships across time.","tags":[],"title":"Every Word has its History: Interactive Exploration and Visualization of Word Sense Evolution","type":"publication"},{"authors":["Nina Tahmasebi"],"categories":null,"content":"","date":1538033400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538033400,"objectID":"fd7eb6d85952da283f150aeafe297399","permalink":"//localhost:1313/talk/keynoteedh/","publishdate":"2018-09-27T09:30:00+02:00","relpermalink":"/talk/keynoteedh/","section":"talk","summary":"For the last decade, automatic detection of word sense change has primarily focused on detecting the main changes in meaning of a word. Most current methods rely on new, powerful embedding technologies, but do not differentiate between different senses of a word, which is needed in many applications in the digital humanities. Of course, this radically reduces the complexity, but often fails to answer questions like: what changed and how, and when did the change occur? In this talk, I will present methods for automatically detecting sense change from large amounts of diachronic data. I will focus on a study on a Historical Swedish Newspaper Corpus, the Kubhist dataset with digitized Swedish newspapers from 1749-1925. I will present our work with detecting and correcting OCR errors, normalizing spelling variations, and creating representations for individual words using a popular neural embedding method, namely Word2Vec. Methods for creating (neural) word embeddings are the state-of-the-art in sense change detection, and many other areas of study, and mainly studied on English corpora where the size of the datasets are sufficiently large. I will discuss the limitations of such methods for this particular context; fairly small-sized data with a high error rate as is common in a historical context for most languages. In addition, I will discuss the particularities of text mining methods for digital humanities and what is needed to bridge the gap between computer science and the digital humanities.","tags":["Digital humanities","Data science","Language Change Detection"],"title":"Estonian Digital Humanities Conference 2018","type":"talk"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536444000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536444000,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"//localhost:1313/tutorial/example/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["Jacobo Rouces","Nina Tahmasebi","Lars Borin","Stian Rødven Eide "],"categories":null,"content":"","date":1526594400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526594400,"objectID":"0a7d5896c6ddd079adf1e2f7a3664df8","permalink":"//localhost:1313/publication/2018-lrec2018-2/","publishdate":"2018-05-18T00:00:00+02:00","relpermalink":"/publication/2018-lrec2018-2/","section":"publication","summary":"The natural language processing subfield known as sentiment analysis or opinion mining has seen an explosive expansion over the last decade or so, and sentiment analysis has become a standard item in the NLP toolbox. Still, many theoretical and methodological questions remain unanswered and resource gaps unfilled. Most work on automated sentiment analysis has been done on English and a few other languages; for most written languages of the world, this tool is not available. This paper describes the development of an extensive sentiment lexicon for written (standard) Swedish. We investigate different methods for developing a sentiment lexicon for Swedish. We use an existing gold standard dataset for training and testing. For each word sense from the SALDO Swedish lexicon, we assign a real value sentiment score in the range [-1,1] and produce a sentiment label. We implement and evaluate three methods: a graph-based method that iterates over the SALDO structure, a method based on random paths over the SALDO structure and a corpus-driven method based on word embeddings. The resulting sense-disambiguated sentiment lexicon (SenSALDO) is an open source resource and freely available from Språkbanken, The Swedish Language Bank at the University of Gothenburg. ","tags":[],"title":"Generating a Gold Standard for a Swedish Sentiment Lexicon","type":"publication"},{"authors":["Jacobo Rouces","Nina Tahmasebi","Lars Borin","Stian Rødven Eide "],"categories":null,"content":"","date":1526594400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526594400,"objectID":"0556817d9fd86abe040926d68edd8c01","permalink":"//localhost:1313/publication/2018-lrec2018-1/","publishdate":"2018-05-18T00:00:00+02:00","relpermalink":"/publication/2018-lrec2018-1/","section":"publication","summary":"We create a gold standard for sentiment annotation of Swedish terms, using the freely available SALDO lexicon and the Gigaword corpus. For this purpose, we employ a multi-stage approach combining corpus-based frequency sampling, direct score annotation and Best-Worst Scaling. In addition to obtaining a gold standard, we analyze the data from our process and we draw conclusions about the optimal sentiment model. ","tags":[],"title":"SenSALDO: Creating a Sentiment Lexicon for Swedish","type":"publication"},{"authors":["Nina Tahmasebi"],"categories":null,"content":"","date":1520377200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520377200,"objectID":"9b1f3699d08cce4283bed706e8849664","permalink":"//localhost:1313/publication/2018-word2vec/","publishdate":"2018-03-07T00:00:00+01:00","relpermalink":"/publication/2018-word2vec/","section":"publication","summary":"Detecting word sense changes can be of great interest in the field of digital humanities. Thus far, most investigations and automatic methods have been developed and carried out on English text and most recent methods make use of word embeddings. This paper presents a study on using Word2Vec, a neural word embedding method, on a Swedish historical newspaper collection. Our study includes a set of 11 words and our focus is the quality and stability of the word vectors over time. We investigate if a word embedding method like Word2Vec can be effectively used on texts where the volume and quality is limited.","tags":[],"title":"A Study on Word2Vec on a Historical Swedish Newspaper Corpus","type":"publication"},{"authors":["Jacobo Rouces","Lars Borin","Nina Tahmasebi","Stian Rødven Eide "],"categories":null,"content":"","date":1520377200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520377200,"objectID":"1321d387ebdd88aafc585db4a1a0c4b1","permalink":"//localhost:1313/publication/2018-dhn2018/","publishdate":"2018-03-07T00:00:00+01:00","relpermalink":"/publication/2018-dhn2018/","section":"publication","summary":"There is an increasing demand for multilingual sentiment analysis, and most work on sentiment lexicons is still carried out based on English lexicons like WordNet. In addition, many of the non-English sentiment lexicons that do exist have been compiled by (machine) translation from English resources, thereby arguably obscuring possible language-specific characteristics of sentiment-loaded vocabulary. In this paper we describe the creation from scratch of a gold standard for the sentiment annotation of Swedish terms as a first step towards the creation of a full-fledged sentiment lexicon for Swedish. ","tags":[],"title":"Defining a Gold Standard for a Swedish Sentiment Lexicon: Towards Higher-Yield Text Mining in the Digital Humanities","type":"publication"},{"authors":["Sallam Abualhaija","Nina Tahmasebi","Diane Forin","Karl-Heinz Zimmermann"],"categories":null,"content":"","date":1504389600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504389600,"objectID":"4cbf9d36529fbde689597ab49e2cf7bd","permalink":"//localhost:1313/publication/2017-ranlp-2/","publishdate":"2017-09-03T00:00:00+02:00","relpermalink":"/publication/2017-ranlp-2/","section":"publication","summary":"Word sense disambiguation is defined as finding the corresponding sense for a target word in a given context, which comprises a major step in text applications.Recently, it has been addressed as an optimization problem. The idea behind is to find a sequence of senses that correspondsto the words in a given context with a maximum semantic similarity. Metaheuristics like simulated annealing and D-Bees provide approximate good-enough solutions, but are usually influenced by the starting parameters. In this paper, we study the parameter tuning for both algorithms within the word sense disambiguation problem. The experiments are conducted on different datasets to cover different disambiguation scenarios. We show that D-Bees is robust and less sensitive towards the initial parameters compared to simulated annealing, hence, it is sufficient to tune the parameters once and reuse them for different datasets, domains or languages.","tags":[],"title":"Parameter Transfer across Domains for Word Sense Disambiguation","type":"publication"},{"authors":["Nina Tahmasebi","Thomas Risse"],"categories":null,"content":"","date":1504303200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504303200,"objectID":"2c71b717a4089bc1698aa24994bc19ef","permalink":"//localhost:1313/publication/2017-ranlp-1/","publishdate":"2017-09-02T00:00:00+02:00","relpermalink":"/publication/2017-ranlp-1/","section":"publication","summary":"We present a method for detecting word sense changes by utilizing automatically induced word senses. Our method works on the level of individual senses and allows a word to have e.g. one stable sense and then add a novel sense that later experiences change. Senses are grouped based on polysemy to find linguistic concepts and we can find broadening and narrowing as well as novel (polysemous and homonymic) senses. We evaluate on a testset, present recall and estimates of the time between expected and found change.","tags":[],"title":"Finding Individual Word Sense Changes and their Delay in Appearance","type":"publication"},{"authors":["Nina Tahmasebi","Thomas Risse"],"categories":null,"content":"","date":1504303200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504303200,"objectID":"db676a5c4ec44cd21f28788b2cfa56ab","permalink":"//localhost:1313/publication/2017-tpdl2017/","publishdate":"2017-09-02T00:00:00+02:00","relpermalink":"/publication/2017-tpdl2017/","section":"publication","summary":"With advances in technology and culture, our language changes. We invent new words, add or change meanings of existing words and change names of existing things. Unfortunately, our language does not carry a memory; words, expressions and meanings used in the past are forgotten over time. When searching and interpreting content from archives, language changes pose a great challenge. In this paper, we present results of automatic word sense change detection and show the utility for archive users as well as digital humanities’ research. Our method is able to capture changes that relate to the usage and culture of a word that cannot easily be found using dictionaries or other resources.","tags":[],"title":"On the Uses of Word Sense Change for Research in the Digital Humanities","type":"publication"},{"authors":["Lars Borin","Nina Tahmasebi","Elena Volodina","Stefan Ekman","Caspar Jordan","Jon Viklund","Beáta Megyesi","Jesper Näsman","Anne Palmér","Mats Wirén","Kristina Björkenstam","Gintare Grigonyte","Sofia Gustafson Capková","Tomasz Kosiński"],"categories":null,"content":"","date":1496786400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496786400,"objectID":"2d3f6aff4fff448b0446cbefd71e7bf0","permalink":"//localhost:1313/publication/2017-dh2017/","publishdate":"2017-06-07T00:00:00+02:00","relpermalink":"/publication/2017-dh2017/","section":"publication","summary":"","tags":["Swe-Clarin"],"title":"Swe-Clarin: Language resources and technology for Digital Humanities","type":"publication"},{"authors":["Nina Tahmasebi","Thomas Risse"],"categories":null,"content":"","date":1496268000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496268000,"objectID":"b261dbe6efc5eecab0ae53871a817316","permalink":"//localhost:1313/publication/2017-wsctestset/","publishdate":"2017-06-01T00:00:00+02:00","relpermalink":"/publication/2017-wsctestset/","section":"publication","summary":"This testset consists of 23 terms which have experienced word sense change during the past centuries. The main changes for each term were found using Wikipedia, dictionary.com and the Oxford English Dictionary. We consider major changes in usage as well as changes to sense. In cases where multiple (fine-grained) senses were available, we opted to accept the widest sense. E.g. for the term rock we consider a music sense without any distinction between different types of rock music, because our dataset is unlikely to have fine-grained sense differentiations. If a clear time point cannot be pinpointed, we choose the earliest possible. For comparison purposes we also chose a set of 11 terms that have experienced minimal change during the investigated period, i.e., stable terms.","tags":[],"title":"Word Sense Change Testset","type":"publication"},{"authors":["Jörg Tiedemann","Nina Tahmasebi"],"categories":null,"content":"","date":1495404000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495404000,"objectID":"208247628ef56858061ddea565663166","permalink":"//localhost:1313/publication/2017-nodalida2017/","publishdate":"2017-05-22T00:00:00+02:00","relpermalink":"/publication/2017-nodalida2017/","section":"publication","summary":"","tags":[],"title":"Proceedings of the 21st Nordic Conference on Computational Linguistics","type":"publication"},{"authors":["Bianka Nusko","Nina Tahmasebi","Olof Mogren"],"categories":null,"content":"","date":1465596000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1465596000,"objectID":"37599c88458bceb30b2131620efba158","permalink":"//localhost:1313/publication/2016-swesentim/","publishdate":"2016-06-11T00:00:00+02:00","relpermalink":"/publication/2016-swesentim/","section":"publication","summary":"In this paper we will present our ongoing project to build and evaluate a sentiment lexicon for Swedish. Our main resource is SALDO, a lexical resource of modern Swedish developed at Språkbanken, University of Gothenburg. Using a semi-supervised approach, we expand a manually chosen set of six core words using parent-child relations based on the semantic network structure of SALDO. At its current stage the lexicon consists of 175 seeds, 633 children, and 1319 grandchildren. ","tags":[],"title":"Building a Sentiment Lexicon for Swedish","type":"publication"},{"authors":["Stian Rødven Eide ","Nina Tahmasebi","Lars Borin"],"categories":null,"content":"","date":1465596000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1465596000,"objectID":"338c6677a9d755a15c9eacd86af91cb1","permalink":"//localhost:1313/publication/2016-gigawords2016/","publishdate":"2016-06-11T00:00:00+02:00","relpermalink":"/publication/2016-gigawords2016/","section":"publication","summary":"In this paper we present a dataset of contemporary Swedish containing one billion words. The dataset consists of a wide range of sources, all annotated using a state-of-the-art corpus annotation pipeline, and is intended to be a static and clearly versioned dataset. This will facilitate reproducibility of experiments across institutions and make it easier to compare NLP algorithms on contemporary Swedish. The dataset contains sentences from 1950 to 2015 and has been carefully designed to feature a good mix of genres balanced over each included decade. The sources include literary, journalistic, academic and legal texts, as well as blogs and web forum entries. ","tags":[],"title":"The Swedish Culturomics Gigaword Corpus: A One Billion Word Swedish Reference Dataset for NLP","type":"publication"},{"authors":null,"categories":null,"content":"Recently, scholars have begun to draw on the massive amounts of text data made available through Google\u0026rsquo;s large-scale book digitization project in order to track the development of cultural concepts and words over the last two centuries, announcing a new field of research named \u0026ldquo;culturomics\u0026rdquo; by its originators.\nHowever, these initial studies have been (rightly) criticized for not referring to relevant work in linguistics and language technology. Nevertheless, the basic premise of this endeavor is eminently timely. Even if we restrict ourselves to the written language, vast amounts of new Swedish text are produced every year and older texts are being digitized apace in cultural heritage projects. This abundance of text contains enormous riches of information. However, the volumes of Swedish text available in digital form have grown far beyond the capacity of even the the fastest reader, leaving automated semantic processing of the texts as the only realistic option for accessing and using this information.\nThe main aim of this research program is to advance the state of the art in language technology resources and methods for semantic processing of Swedish text, in order to provide researchers and others with more sophisticated tools for working with the information contained in large volumes of digitized text, e.g., by being able to correlate and compare the content of texts and text passages on a large scale.\nThe project will focus on the theoretical and methodological advancement of the state of the art in extracting and correlating information from large volumes of Swedish text using a combination of knowledge-based and statistical methods. One central aim of this project will be to develop methodology and applications in support of research in disciplines where text is an important primary research data source, primarily the humanities and social sciences (HSS).\nThe innovative core of the project will be the exploration of how to best combine knowledge-rich but sometimes resource-consuming LT processing with statistical machine-learning and data-mining approaches.\nProject pages\n","date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"0b34252711337bc765cda90fe72b29f1","permalink":"//localhost:1313/project/culturomics/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/culturomics/","section":"project","summary":"Towards a Knowledge-based Culturomics.","tags":["Data Science, Language Change Detection, Sentiment Mining"],"title":"Culturomics","type":"project"},{"authors":["Malin Ahlberg","Peter Andersson","Markus Forsberg","Nina Tahmasebi"],"categories":null,"content":"","date":1430431200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430431200,"objectID":"85c2b38becfe9be5de1aa52d7bc029a9","permalink":"//localhost:1313/publication/2015nodalida2015/","publishdate":"2015-05-01T00:00:00+02:00","relpermalink":"/publication/2015nodalida2015/","section":"publication","summary":"We present a case study on supervised classification of Swedish pseudo-coordination (SPC). The classification is attempted on the type-level with data collected from two data sets: a blog corpus and a fiction corpus. Two small experiments were designed to evaluate the feasability of this task. The first experiment explored a classifier’s ability to discriminate pseudo-coordinations from ordinary verb coordinations, given a small labeled data set created during the experiment. The second experiment evaluated how well the classifier performed at detecting and ranking SPCs in a set of unlabeled verb coordinations, to investigate if it could be used as a semi-automatic discovery procedure to find new SPCs.","tags":[],"title":"A case study on supervised classification of Swedish pseudo-coordination","type":"publication"},{"authors":["Helge Holzmann","Nina Tahmasebi","Thomas Risse"],"categories":null,"content":"","date":1427839200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427839200,"objectID":"9aad7a08897c37c7f5b93dc664bab51f","permalink":"//localhost:1313/publication/2015-ijdl2015-blogs/","publishdate":"2015-04-01T00:00:00+02:00","relpermalink":"/publication/2015-ijdl2015-blogs/","section":"publication","summary":"Advancements in technology and culture lead to changes in our language. These changes create a gap between the language known by users and the language stored in digital archives. It affects user’s possibility to firstly find content and secondly interpret that content. In a previous work, we introduced our approach for named entity evolution recognition (NEER) in newspaper collections. Lately, increasing efforts in Web preservation have led to increased availability of Web archives covering longer time spans. However, language on the Web is more dynamic than in traditional media and many of the basic assumptions from the newspaper domain do not hold for Web data. In this paper we discuss the limitations of existing methodology for NEER. We approach these by adapting an existing NEER method to work on noisy data like the Web and the Blogosphere in particular. We develop novel filters that reduce the noise and make use of Semantic Web resources to obtain more information about terms. Our evaluation shows the potentials of the proposed approach.","tags":[],"title":"Named entity evolution recognition on the Blogosphere","type":"publication"},{"authors":["Nina Tahmasebi","Lars Borin","Gabriele Capannini","Devdatt Dubhashi","Peter Exner","Markus Forsberg","Gerhard Gossen","Fredrik D. Johansson","Richard Johansson","Mikael Kågebäck","Olof Mogren","Pierre Nugues","Thomas Risse"],"categories":null,"content":"","date":1427839200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427839200,"objectID":"fc7ff7c8e7923301bff9c77f5022c76d","permalink":"//localhost:1313/publication/2015-ijdl2015-cult/","publishdate":"2015-04-01T00:00:00+02:00","relpermalink":"/publication/2015-ijdl2015-cult/","section":"publication","summary":"The concept of culturomics was born out of the availability of massive amounts of textual data and the interest to make sense of cultural and language phenomena over time. Thus far however, culturomics has only made use of, and shown the great potential of, statistical methods. In this paper, we present a vision for a knowledge-based culturomics that complements traditional culturomics. We discuss the possibilities and challenges of combining knowledge-based methods with statistical methods and address major challenges that arise due to the nature of the data; diversity of sources, changes in language over time as well as temporal dynamics of information in general. We address all layers needed for knowledge-based culturomics, from natural language processing and relations to summaries and opinions.","tags":[],"title":"Visions and open challenges for a knowledge-based culturomics","type":"publication"},{"authors":["Mikael Kågebäck","Olof Mogren","Nina Tahmasebi","Devdatt Dubhashi"],"categories":null,"content":"","date":1398808800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398808800,"objectID":"903e7892b09bb9bc616e07ca045aeded","permalink":"//localhost:1313/publication/2014-cvsc2014/","publishdate":"2014-04-30T00:00:00+02:00","relpermalink":"/publication/2014-cvsc2014/","section":"publication","summary":"There is an increasing demand for multilingual sentiment analysis, and most work on sentiment lexicons is still carried out based on English lexicons like WordNet. In addition, many of the non-English sentiment lexicons that do exist have been compiled by (machine) translation from English resources, thereby arguably obscuring possible language-specific characteristics of sentiment-loaded vocabulary. In this paper we describe the creation from scratch of a gold standard for the sentiment annotation of Swedish terms as a first step towards the creation of a full-fledged sentiment lexicon for Swedish. ","tags":[],"title":"Extractive Summarization using Continuous Vector Space Models","type":"publication"},{"authors":["Nina Tahmasebi"],"categories":null,"content":"","date":1384297200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1384297200,"objectID":"636661b89b8ed0435fb046569f8dc139","permalink":"//localhost:1313/publication/2013-phdthesis/","publishdate":"2013-11-13T00:00:00+01:00","relpermalink":"/publication/2013-phdthesis/","section":"publication","summary":"This testset consists of 23 terms which have experienced word sense change during the past centuries. The main changes for each term were found using Wikipedia, dictionary.com and the Oxford English Dictionary. We consider major changes in usage as well as changes to sense. In cases where multiple (fine-grained) senses were available, we opted to accept the widest sense. E.g. for the term rock we consider a music sense without any distinction between different types of rock music, because our dataset is unlikely to have fine-grained sense differentiations. If a clear time point cannot be pinpointed, we choose the earliest possible. For comparison purposes we also chose a set of 11 terms that have experienced minimal change during the investigated period, i.e., stable terms.","tags":[],"title":"Models and Algorithms for Automatic Detection of Language Evolution","type":"publication"},{"authors":["Helge Holzmann","Nina Tahmasebi","Thomas Risse"],"categories":null,"content":"","date":1364767200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364767200,"objectID":"a7732c7897a94111f38eac503384f95f","permalink":"//localhost:1313/publication/2013-sda2013--blogneer/","publishdate":"2013-04-01T00:00:00+02:00","relpermalink":"/publication/2013-sda2013--blogneer/","section":"publication","summary":"The introduction of Social Media allowed more people to publish texts by removing barriers that are technical but also social such as the editorial controls that exist in traditional media. The resulting language tends to be more like spoken language because people adapt their use to the medium. Since spoken language is more dynamic, more new and short lived terms are introduced also in written format on the Web. In Tahmasebi et al we presented an unsupervised method for Named Entity Evolution Recognition (NEER) to find name changes in newspaper collections. In this paper we present BlogNEER, an extension to apply NEER on blog data. The language used in blogs is often closer to spoken language than to language used in traditional media. BlogNEER introduces a novel semantic filtering method that makes use of Semantic Web resources (i.e., DBpedia) to gain more information about terms. We present the approach of BlogNEER and initial results that show the potentials of the approach.","tags":[],"title":"BlogNEER: Applying Named Entity Evolution Recognition on the Blogospheres","type":"publication"},{"authors":["Nina Tahmasebi","Kai Niklas","Gideon Zenz","Thomas Risse"],"categories":null,"content":"","date":1364767200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364767200,"objectID":"c421574b5bfe4fa26d456c24cd4ef5b8","permalink":"//localhost:1313/publication/2012-ijdl2012-ontheapplicability/","publishdate":"2013-04-01T00:00:00+02:00","relpermalink":"/publication/2012-ijdl2012-ontheapplicability/","section":"publication","summary":"As language evolves over time, documents stored in long- term archives become inaccessible to users. Automatically, detecting and handling language evolution will become a necessity to meet user’s information needs. In this paper, we investigate the performance of modern tools and algorithms applied on modern English to find word senses that will later serve as a basis for finding evolution. We apply the curvature clustering algorithm on all nouns and noun phrases extracted from The Times Archive (1785–1985). We use natural language processors for part-of-speech tagging and lemmatization and report on the performance of these processors over the entire period. We evaluate our clusters using WordNet to verify whether they correspond to valid word senses. Because The Times Archive contains OCR errors, we investigate the effects of such errors on word sense discrimination results. Finally, we present a novel approach to correct OCR errors present in the archive and show that the coverage of the curvature clustering algorithm improves. We increase the number of clusters by 24 %. To verify our results, we use the New York Times corpus (1987–2007), a recent collection that is considered error free, as a ground truth for our experiments. We find that after correcting OCR errors in The Times Archive, the performance of word sense discrimination applied on The Times Archive is comparable to the ground truth.","tags":[],"title":"On the applicability of word sense discrimination on 201 years of modern english","type":"publication"},{"authors":["Nina Tahmasebi","Thomas Risse"],"categories":null,"content":"","date":1364767200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364767200,"objectID":"1dcf433884175a802a72265bf2ee4b7c","permalink":"//localhost:1313/publication/2013-sda2013/","publishdate":"2013-04-01T00:00:00+02:00","relpermalink":"/publication/2013-sda2013/","section":"publication","summary":"With advancements in technology and culture, our language changes. We invent new words, add or change meanings of existing words and change names of existing things. Left untackled, these changes in language create a gap between the language known by users and the language stored in our digital archives. In particular, they affect our possibility to firstly  find content and secondly interpret that content. In this paper we discuss the limitations brought on by language evolution and existing methodology for automatically finding evolution. We discuss measured needed in the near future to ensure semantically accessible digital archives for long-term preservation.","tags":[],"title":"The Role of Language Evolution in Digital Archives","type":"publication"},{"authors":["Nina Tahmasebi","Gerhard Gossen","Nattiya Kanhabua","Helge Holzmann","Thomas Risse"],"categories":null,"content":"","date":1355526000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1355526000,"objectID":"78971415797dbc3cd19a633361bb93bf","permalink":"//localhost:1313/publication/2012-coling2012/","publishdate":"2012-12-15T00:00:00+01:00","relpermalink":"/publication/2012-coling2012/","section":"publication","summary":"High impact events, political changes and new technologies are reflected in our language and lead to constant evolution of terms, expressions and names. Not knowing about names used in the past for referring to a named entity can severely decrease the performance of many computational linguistic algorithms. We propose NEER, an unsupervised method for named entity evolution recognition independent of external knowledge sources. We find time periods with high likelihood of evolution. By analyzing only these time periods using a sliding window co-occurrence method we capture evolving terms in the same context. We thus avoid comparing terms from widely different periods in time and overcome a severe limitation of existing methods for named entity evolution, as shown by the high recall of 90% on the New York Times corpus. We compare several relatedness measures for filtering to improve precision. Furthermore, using machine learning with minimal supervision improves precision to 94%.","tags":[],"title":"NEER: An Unsupervised Method for Named Entity Evolution Recognition","type":"publication"},{"authors":["Helge Holzmann","Gerhard Gossen","Nina Tahmasebi"],"categories":null,"content":"","date":1355526000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1355526000,"objectID":"0621e4d6a74def97ad0dbe28876a904c","permalink":"//localhost:1313/publication/2012-coling-fokas/","publishdate":"2012-12-15T00:00:00+01:00","relpermalink":"/publication/2012-coling-fokas/","section":"publication","summary":"High impact events, political changes and new technologies are reflected in our language and lead to constant evolution of terms, expressions and names. This makes search using standard search engines harder, as users need to know all different names used over time to formulate an appropriate query. The fokas search engine demonstrates the impact of enriching search results with results for all temporal variants of the query. It uses NEER, a method for named entity evolution recognition. For each query term, NEER detects temporal variants and presents these to the user. A chart with term frequencies helps users choose among the proposed names to extend the query. This extended query captures relevant documents using temporal variants of the original query and improves overall quality. We use the New York Times corpus which, with its 20 year timespan and many name changes, constitutes a good collection to demonstrate NEER and fokas.","tags":[],"title":"fokas: Formerly Known As -- A Search Engine Incorporating Named Entity Evolution","type":"publication"},{"authors":["Nina Tahmasebi","Gerhard Gossen","Thomas Risse"],"categories":null,"content":"","date":1346536800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1346536800,"objectID":"791a4297f0c34bccc1b7f9a0392bdc44","permalink":"//localhost:1313/publication/2012-tpdl2012/","publishdate":"2012-09-02T00:00:00+02:00","relpermalink":"/publication/2012-tpdl2012/","section":"publication","summary":"Knowing the behavior of terms in written texts can help us tailor fit models, algorithms and resources to improve access to digital libraries and help us answer information needs in longer spanning archives. In this paper we investigate the behavior of English written text in blogs in comparison to traditional texts from the New York Times, The Times Archive, and the British National Corpus. We show that user generated content, similar to spoken content, differs in characteristics from ‘professionally’ written text and experiences a more dynamic behavior.","tags":[],"title":"Which Words Do You Remember? Temporal Properties of Language Use in Digital Archives","type":"publication"},{"authors":["Bogdan Pogorelc","Artur Lugmayr","Björn Stockleben","Radu-Daniel Vatavu","Nina Tahmasebi","Estefanía Serral","Emilija Stojmenova","Bojan Imperl","Thomas Risse","Gideon Zenz","Matjaz Gams"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"70ce7b90bc650951094f9d4eca6ae97b","permalink":"//localhost:1313/publication/2012-mta2012-ambientbloom/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/2012-mta2012-ambientbloom/","section":"publication","summary":"Semantic ambient media are the novel trend in the world of media reaching from the pioneering subareas such as ambient advertising to the new and emerging subareas such as ambient assisted living. They will likely shape the upcoming years in terms of modeling smart environments and also media consumption and interaction. This work analyzes semantic ambient media by considering business models, content and media, interaction design and consumer experience, and methods and techniques that are important to create this new form of media. Discussion is led using the state-of-the-art event of the semantic ambient media, which is the annual international workshop on Semantic Ambient Media Experience (SAME). The study also creates a vision for how ambient media will evolve and how they will look like in the future decade.","tags":[],"title":"Ambient bloom: new business, content, design and models to increase the semantic ambient media experience","type":"publication"},{"authors":["Gideon Zenz","Nina Tahmasebi","Thomas Risse"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"fed450ef6d2366e2a6a1446cdf228f2d","permalink":"//localhost:1313/publication/2012-mta2012/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/2012-mta2012/","section":"publication","summary":"Knowing about the evolution of a term can significantly help when searching for relevant information, especially in case of sudden evolutions (e.g. as of dramatical changes in political situations). Here, some terms get a completely new meaning or are used in new or different ways. In mobile situations it is important to be able to effectively retrieve information, since this is usually done in a hurry and interaction possibilities with mobile devices are limited. In this paper we describe a methodology using word sense discrimination to discover term evolution. We present two mobile interfaces for easy access and exploration of this evolution, as well as a user-study to show its usefulness. We conclude the paper with an outlook of further research possibilities in this new topic.","tags":[],"title":"Towards mobile language evolution exploitation","type":"publication"},{"authors":["Christopher Kunz","Nina Tahmasebi","Thomas Risse","Matthew Smith"],"categories":null,"content":"","date":1304200800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1304200800,"objectID":"9ef482bb7b0f44df398b9e9a26705ab3","permalink":"//localhost:1313/publication/2011-grid2011/","publishdate":"2011-05-01T00:00:00+02:00","relpermalink":"/publication/2011-grid2011/","section":"publication","summary":"Proxy Credentials serve as a principal for authentication and authorization in the Grid. Despite their limited lifetime, they can be intercepted and abused by an attacker. We counter this threat by enabling Grid users to track their credentials? use in Grid infrastructures, reporting all authentication and delegation operations to an auditing service. Our approach combines modifications to the security infrastructure with a Bayesian classifier in order to provide a reliable method for detecting abusive Grid credential usage and alerting the legitimate user. To validate this approach we created an extensive Grid simulation, simulating different types of legitimate and illegitimate use of credentials. Our experiments show that we can detect 99.5% of all abuse and our solution can thus help to increase security in the Grid.","tags":[],"title":"Detecting Credential Abuse in the Grid using Bayesian Networks","type":"publication"},{"authors":null,"categories":null,"content":"The vision of the ARCOMEM project is to leverage the Wisdom of the Crowds for content appraisal, selection and preservation, so that archives reflect collective memory and social content perception\nARCOMEM is about memory institutions like archives, museums, and libraries in the age of the Social Web. Memory institutions are more important now than ever: as we face greater economic and environmental challenges we need our understanding of the past to help us navigate to a sustainable future. This is a core function of democracies, but this function faces stiff new challenges in face of the Social Web, and of the radical changes in information creation, communication and citizen involvement that currently characterise our information society (e.g., there are now more social network hits than Google searches). Social media are becoming more and more pervasive in all areas of life. In the UK, for example, it is now not unknown for a government minister to answer a parliamentary question using Twitter, and this material is both ephemeral and highly contextualised, making it increasingly difficult for a political archivist to decide what to preserve.\nThis new world challenges the relevance and power of our memory institutions. To respond to these challenges, ARCOMEM\u0026rsquo;s aim is to:\n help transform archives into collective memories that are more tightly integrated withtheir community of users exploit Social Web and the wisdom of crowds to make Web archiving a more selective and meaning-based process  To do this, the project team will provide innovative tools for archivists to help exploit the new media and make our organisational memories richer and more relevant. This will be addressed in three ways:\n First, it will be demonstrated how social media can help archivists select material for inclusion, providing content appraisal via the social web. Second, it will be shown how social media mining can enrich archives, moving towards structured preservation around semantic categories. Third, reserach will explore social, community and user-based archive creation methods.  As results of this activity the outcomes of the ARCOMEM project will include:\n innovative models and tools for Social Web driven content appraisal and selection, and intelligent content acquisition novel methods for Social Web analysis, Web crawling and mining, event and topicdetection and consolidation, and multimedia content mining reusable components for archive enrichment and contextualization two complementary example applications, the first for media-related Web archives and the second for political archives a standards-oriented ARCOMEM demonstration system  The impact of these outcomes will be to a) reduce the risk of losing irreplaceable ephemeral webinformation, b) facilitate cost-efficient and effective archive creation, and c) support the creation of more valuable archives. This has the potential to strengthen our democracies\u0026rsquo; understanding of the past, in order to better direct our present towards viable and sustainable modes of living, and thus to make a contribution to the future of Europe and beyond.\nThe Arcomem project was funded by the European Commission under Project No. 270239\nProject pages\n","date":1293836400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293836400,"objectID":"a85ebda1e6fea89eac2c0da6379fe92b","permalink":"//localhost:1313/project/arcomem/","publishdate":"2011-01-01T00:00:00+01:00","relpermalink":"/project/arcomem/","section":"project","summary":"From Collect-All Archives to Community Memories – Leveraging the Wisdom of the Crowds for Intelligent Preservation","tags":["Digital Preservation","Web Harvesting","Language Change Detection"],"title":"ARCOMEM","type":"project"},{"authors":["Nina Tahmasebi","Gideon Zenz","Theresa Iofciu","Thomas Risse"],"categories":null,"content":"","date":1282428000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1282428000,"objectID":"c3454c7a0cd725c89941203d320a2a1f","permalink":"//localhost:1313/publication/2010-iwaw2010/","publishdate":"2010-08-22T00:00:00+02:00","relpermalink":"/publication/2010-iwaw2010/","section":"publication","summary":"","tags":[],"title":"Terminology Evolution Module for Web Archives in the LiWA Context","type":"publication"},{"authors":["Nina Tahmasebi"],"categories":null,"content":"","date":1277157600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277157600,"objectID":"7190ed5e88d75f4b0d2140428b280cc5","permalink":"//localhost:1313/publication/2009-otm2009/","publishdate":"2010-06-22T00:00:00+02:00","relpermalink":"/publication/2009-otm2009/","section":"publication","summary":"As archives contain documents that span over a long period of time, the language used to create these documents and the language used for querying the archive can differ. This difference is due to evolution in both terminology and semantics and will cause a significant number of relevant documents being omitted. A static solution is to use query expansion based on explicit knowledge banks such as thesauri or ontologies. However as we are able to archive resources with more varied terminology, it will be infeasible to use only explicit knowledge for this purpose. There exist only few or no thesauri covering very domain specific terminologies or slang as used in blogs etc. In this Ph.D. thesis we focus on automatically detecting terminology evolution in a completely unsupervised manner as described in this technical paper.","tags":[],"title":"Automatic Detection of Terminology Evolution","type":"publication"},{"authors":["Nina Tahmasebi","Kai Niklas","Thomas Theuerkauf","Thomas Risse"],"categories":null,"content":"","date":1277157600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277157600,"objectID":"daa3d58199a83f60ab237f8affaae025","permalink":"//localhost:1313/publication/2010-jcdl2010/","publishdate":"2010-06-22T00:00:00+02:00","relpermalink":"/publication/2010-jcdl2010/","section":"publication","summary":"Word sense discrimination is the first, important step towards automatic detection of language evolution within large, historic document collections. By comparing the found word senses over time, we can reveal and use important information that will improve understanding and accessibility of a digital archive. Algorithms for word sense discrimination have been developed while keeping today's language in mind and have thus been evaluated on well selected, modern datasets. The quality of the word senses found in the discrimination step has a large impact on the detection of language evolution. Therefore, as a first step, we verify that word sense discrimination can successfully be applied to digitized historic documents and that the results correctly correspond to word senses. Because accessibility of digitized historic collections is influenced also by the quality of the optical character recognition (OCR), as a second step we investigate the effects of OCR errors on word sense discrimination results. All evaluations in this paper are performed on The Times Archive, a collection of newspaper articles from 1785 - 1985.","tags":[],"title":"Using Word Sense Discrimination on Historic Document Collections","type":"publication"},{"authors":["Nina Tahmasebi","Sukriti Ramesh","Thomas Risse"],"categories":null,"content":"","date":1250892000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1250892000,"objectID":"650c40a27349ca3239fba7f1a7eff988","permalink":"//localhost:1313/publication/2009-iwaw2009/","publishdate":"2009-08-22T00:00:00+02:00","relpermalink":"/publication/2009-iwaw2009/","section":"publication","summary":"The archival of content like publications or web pages is just the first step toward ?full? content preservation. It also has to be guaranteed that content can be found and interpreted in the long run. The correspondence between the terminology used for querying and the one used in content objects to be retrieved, is a crucial prerequisite for effective retrieval technology. However, as terminology evolves over time, a growing gap opens between older documents in (longterm) archives and the active language used for querying such archives. Thus, technologies for detecting and systematically handling terminology evolution are required to ensure *semantic* accessibility of archived content in the long run. The core of our approach is to derive mappings between terminologies originating from different times by the fusion of term concept graphs. To verify the suitability of our approach, we present first results of experiments conducted on The Times archive that covers 200 years of documents. In addition, we discuss how our approach can be applied to web archives and the challenges that arise from this.","tags":[],"title":"First Results on Detecting Term Evolutions","type":"publication"},{"authors":["Nina Tahmasebi","Teresa Iofciu","Thomas Risse","Claudia Niederee","Wolf Siberski"],"categories":null,"content":"","date":1219356000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1219356000,"objectID":"375612b60d1e835d2614f1ce7d45ec49","permalink":"//localhost:1313/publication/2008-iwaw2008/","publishdate":"2008-08-22T00:00:00+02:00","relpermalink":"/publication/2008-iwaw2008/","section":"publication","summary":"The correspondence between the terminology used for querying and the one used in content objects to be retrieved, is a crucial prerequisite for effective retrieval technology. How- ever, as terminology is evolving over time, a growing gap opens up between older documents in (long-term) archives and the active language used for querying such archives. Thus, technologies for detecting and systematically handling terminology evolution are required to ensure semantic accessibility of (Web) archive content on the long run. As a starting point for dealing with terminology evolution this paper formalizes the problem and discusses issues, first ideas and relevant technologies.","tags":[],"title":"Terminology Evolution in Web Archiving: Open Issues","type":"publication"},{"authors":null,"categories":null,"content":"Web content plays an increasingly important role in the knowledge-based society, and the preservation and long-term accessibility of Web history has high value (e.g., for scholarly studies, market analyses, intellectual property disputes, etc.). There is strongly growing interest in its preservation by library and archival organizations as well as emerging industrial services. Web content characteristics (high dynamics, volatility, contributor and format variety) make adequate Web archiving a challenge.\nLiWA will look beyond the pure “freezing” of Web content snapshots for a long time, transforming pure snapshot storage into a “Living” Web Archive. “Living” refers to a) long term interpretability as archives evolve, b) improved archive fidelity by filtering out irrelevant noise and c) considering a wide variety of content. LiWA will extend the current state of the art and develop the next generation of Web content capture, preservation, analysis, and enrichment services to improve fidelity, coherence, and interpretability of web archives. By developing methods which improve archive fidelity, the project will contribute to adequate preservation of complete and high-quality content. By developing methods for improved archive coherence and interpretability, the project contributes to ensuring its long-term usability. LiWA RTD will focus on innovative methods for content capturing, filtering out spam and other noise, improving temporal archive coherence, and dealing with semantic and terminology evolution. Two exemplary LiWA applications - focusing on audiovisual streams and social web content, respectively - will show the benefits of advanced Web archiving to interested stakeholders. To ensure demand-driven RTD development and broad, sustained project impact, the LiWA consortium will closely work with the International Internet Preservation Consortium (IIPC) as well as important library and archiving organizations, two of which are members of LiWA.\nThe LiWA project was funded by the European Commission under Project No. 21626\nProject pages\n","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"34452a5b43a021dbec1e85821d9208b0","permalink":"//localhost:1313/project/liwa/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/project/liwa/","section":"project","summary":"Developing the next generation web archive technologies - Living Web Archives","tags":["Digital Preservation","Web Harvesting","Language Change Detection"],"title":"LiWA","type":"project"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne\r Two\r Three\r\nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"//localhost:1313/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]