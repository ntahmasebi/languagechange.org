+++
title = "3rd International Workshop on Computational Approaches to Historical Language Change 2022 (LChange'22)"
date = 2021-11-25T09:30:00 # Schedule page publish date.
draft = false

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
time_start = 2022-05-26T09:30:00
#time_end = 2030-06-01T15:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Nina Tahmasebi", "Lars Borin", "Simon Hengchen", "Syrielle Montariol", "Haim Dubossarsky", "Andrey Kutuzov"]

# Abstract and optional shortened version.
#abstract = "
abstract = "LChange'22 is the third workshop for computational approaches to historical language change with the focus on digital text corpora. This year, the workshop will feature a shared task on semantic change detection for Spanish. Come join us for this exciting adventure!"
abstract_short = "Third LChange workshop co-located with ACL2022"

# Name of event and optional event URL.
event = "3rd International Workshop on Computational Approaches to Historical Language Change 2022 (LChange'22)"
#event_url = "https://dh.org.ee/events/dhe2018/"


# Location of event.
location = "Bangkok, Thailand"

# Is this a selected talk? (true/false)
selected = true

# Projects (optional).
#   Associate this talk with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["Language Change Detection", "Historical Semantic Change", "Lexical Replacement", "Digital Humanities"]

# Links (optional).
url_pdf = ""
url_slides = ""
url_video = ""
url_code = ""
#<iframe src="

# Does the content use math formatting?
math = true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]

  # Caption (optional)
  #caption = "Image credit: [**Unsplash**](https://unsplash.com/photos/bzdhc5b3Bxs)"

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Right"
  
   # <p>Natural languages change over time. Every language relies on a finite lexicon to express an infinite set of emerging ideas driven by sociocultural and technological development. This tension is often manifested in the historical emergence of novel word forms and meanings, and the obliteration of existing words and word meanings. Compared to other aspects of language where there are rich formal treatments of change (e.g., phonology, grammar), computational approaches to the time-varying properties of word meanings and forms have just begun to take shape in computational linguistics, natural language processing, and related disciplines.</p>
  # <p>Characterizing the time-varying nature of language will have broad implications and applications in multiple fields including linguistics, artificial intelligence, digital humanities, computational cognitive and social sciences. In this workshop, we will bring together the world's pioneers and experts in <strong>computational approaches to historical language change with the focus on digital text corpora.</strong> In doing so, this workshop carries the triple goals of disseminating the state-of-the-art research on diachronic modelling of language change, fostering international cross-disciplinary collaborations, and exploring the fundamental theoretical and methodological challenges in this growing niche of computational linguistic research.</p>
+++


<p>The workshop builds upon <a href="https://languagechange.org/events/2019-acl-lcworkshop/">its first iteration in 2019</a>, and <a href="https://languagechange.org/events/2021-acl-lcworkshop/">the second edition in 20121</a>. It will be colocated with  <a href="https://2022.aclweb.org/">ACL 2022</a> in Dublin , Ireland, as a hybrid event. The workshop dates are not yet fixed but will be on May 26-28, or possibly both dates. This year, LChange will feature a shared task on semantic change detection for Spanish as one track of the workshop. 

We hope to make this third edition another resounding success!</p> 
<p>The call for papers will be similar to last time: all aspects around computational approaches to historical language change with the focus on digital text corpora. If you have published in the field previously, and are inrerested in helping out in the PC to review papers, <a href="mailto:PC-ACLws2022@[remove]languagechange.org" target="_top">send us an email</a>. LChange'19 resulted in a book on <a href="https://langsci-press.org/catalog/book/303">Computational approaches to semantic change</a>, and this year, we are considering a special issue journal for invited workshop papers.</p>


 <h1>Important Dates</h1>

 <ul>
  <li>Feb. 28, 2022: Paper submission</li>
  <li>March 26, 2022: Notification of acceptance</li>
  <li>April 10, 2022: Camera-ready papers due</li>
  <li>May 26-28, 2022: Workshop date (days will be decided upon later)</li>
</ul> 




<h1>Workshop Topics</h1>
<p> This workshop explores state-of-the-art computational methodologies, theories and  digital text resources on exploring the time-varying nature of human language.</p>


<p>The aim of this workshop is three-fold. First, we want to provide pioneering researchers who work on computational methods, evaluation, and large-scale modelling of language change <strong>an outlet for disseminating cutting-edge research on topics concerning language change</strong>. We want to utilize this proposed workshop as a platform for sharing state-of-the-art research progress in this fundamental domain of natural language research.</p>

<p>Second, in doing so we want to <strong>bring together domain experts across disciplines</strong>. 
by connecting researchers in historical linguistics with those that develop and test computational methods for detecting semantic change and laws of semantic change; and those that need knowledge (of the occurrence and shape) of language change, for example, in digital humanities and computational social sciences where text mining is applied to diachronic corpora subject to e.g., lexical semantic change.</p>

<p>Third, the detection and  modelling of language change using diachronic text and text mining raise <strong>undamental theoretical and methodological challenges</strong> for future research.

<p>Besides these goals, this workshop will also support  discussion on the evaluation of computational methodologies for uncovering language change. SemEval2020 Task1 on unsupervised detection of lexical semantic change attracted three figure submission numbers and a total of 21 submitted system papers. Since then, two more tasks have been completed, and we will organize the shared task on Spanish as a part of this workshop.</p>

<p>We invite original research papers from a wide range of topics, including but not limited to:</p>

 <ul>
  <li> Novel methods for detecting diachronic semantic change and lexical replacement</li>
  <li> Automatic discovery and quantitative evaluation of laws of language change</li>
  <li> Computational theories and generative models of language change</li>
  <li> Sense-aware (semantic) change analysis</li>
  <li> Diachronic word sense disambiguation</li>
  <li> Novel methods for diachronic analysis of low-resource languages</li>
  <li> Novel methods for diachronic linguistic data visualization</li>
  <li> Novel applications and implications of language change detection</li>
  <li> Quantification of sociocultural influences on language change</li>
  <li> Cross-linguistic, phylogenetic, and developmental approaches to language change</li>
  <li> Novel datasets for cross-linguistic and diachronic analyses of language</li>
</ul> 


<h1>Shared Task</h1>

<p>The task will have two subtasks organized in two phases respectively: </p>
 <ul>
      <li> discovery, and</li>
      <li>  binary change detection (detection of sense gain or loss vs. neither).</li>
</ul>

<p>Note that <em>discovery</em> introduces additional difficulties for models as compared to the more simple semantic change <em>detection</em>, e.g. because a large number of predictions is required and the target words are not preselected, balanced or cleaned.
Yet, discovery is an important task, with applications such as lexicography where dictionary makers aim to cover the full vocabulary of a language.</p>

<p>The full task description will be published on CodaLab with a short description on the workshop web page.  </p>

<p>Task organizers: Frank D. Zamora-Reina, Felipe Bravo-Marquez, Dominik Schlechtweg.</p>

<h1>Keynote Talks</h1>
To be announced<br>
<!--<br>
 <a href="https://www1.ids-mannheim.de/lexik/personal/koplenig.html">Alexander Koplenig</a> (Leibniz-Institute for the German Language in Mannheim) 
<br> Title of talk: <strong>Two challenges we face when analyzing diachronic corpora </strong><br>
Abstract: In my keynote, I want to discuss two important challenges for the quantitative analysis of diachronic corpora that I believe deserve more attention: <br>
<ul> 
<li>	The first challenge is the systematic influence of the sample size when it comes to basically all measures in quantitative linguistics (Baayen 2001). By analysing the lexical dynamics of the German weekly news magazine “Der Spiegel” (consisting of approximately 365,000 articles and 237,000,000 words that were published between 1947 and 2017), I show that this influence makes it difficult to quantify lexical dynamics and language change. I will also demonstrate that standard sampling approaches do not solve this problem. I will suggest an approach that is able to break the sample size dependence but presupposes access to the full text data (Koplenig, Wolfer & Müller-Spitzer 2019). </li>
<li>	The second challenge is of methodological nature and relates to the problem of representativeness of diachronic corpora. Labov (1994) famously stated that "historical documents survive by chance, not by design, and the selection that is available is the product of an unpredictable series of historical accidents." By using both Google Books Ngram data (Michel et al. 2010; Koplenig 2015; Pechenick, Danforth & Dodds 2015) and publicly available data from the German National Bibliography, I will try to show that the problem is even more fundamental, because there is good reason to believe that composition of the body of published written works (from which a corresponding corpus is supposed to be sampled from) systematically changes as a function of time. This makes it difficult to disentangle actual language change from environmental changes in the textual habitat  (Szmrecsanyi 2016).</li>
</ul> 
<a href="http://people.ds.cam.ac.uk/hd423/">Haim Dubossarsky</a> (Research Fellow at University of Cambridge) <br>
Title of talk: [Semantic change in the time of Machine Learning, doing it right!](/pdf/lchange19/lchange_Dubossarsky.pdf)<br>
-->



<!--TODO_EDIT-->
<h1>Submissions</h1>
<p>We accept three types of submissions, long and short papers, following the ACL2022 style, and the <a href="https://www.aclweb.org/adminwiki/index.php?title=ACL_Policies_for_Submission,_Review_and_Citation">ACL submission policy</a>, and shared task papers.</p>
<!-- 
 <p>Long papers may consist of up to eight (8) pages of content, plus unlimited references, short papers may consist of up to four (4) pages of content; final versions will be given one additional page of content so that reviewers' comments can be taken into account. Abstracts may consist of up to two (2) pages of content, plus unlimited references. </p>
 <p>Submissions should be sent in electronic forms, using the Softconf START conference management system. The <a href="https://www.softconf.com/acl2019/lcworkshop/">submission site</a> is now available.  </p>
-->
<p>Details on paper length and submission proceedure will be posted once released by ACL2022. 

<p>The workshop is planned to last two full days. Submissions are open to all, and are to be submitted anonymously. Workshop papers will be refereed through a double-blind peer review process by at least three reviewers with final acceptance decisions made by the workshop organizers. Shared task participants can choose to submit their papers to the shared task where papers will be reviewed by other task participants, or to the main workshop where they will be reviewed according to the normal workshop proceedure. </p>


<!-- # <h1 id="programme-committee">Programme Committee</h1>
# <font size="30" >
# <table style="font-size: 14px"> 
# <tr>	<th>	Nicholas	A.Lester 	</td>	<th>	Stian Rødven	Eide	</td>	<th>	Bill	Noble	</td>	</tr>
# <tr>	<th>	Yvonne	Adesam	</td>	<th>	Antske	Fokkens	</td>	<th>	Kjetil	Norvag	</td>	</tr>
# <tr>	<th>	Rami	Aly	</td>	<th>	Mats	Fridlund	</td>	<th>	Ella	Rabinovich	</td>	</tr>
# <tr>	<th>	Avishek	Anand	</td>	<th>	Michael	Färber	</td>	<th>	Taraka	Rama	</td>	</tr>
# <tr>	<th>	Timothy	Baldwin	</td>	<th>	Johannes	Hellrich	</td>	<th>	Jacobo	Rouces	</td>	</tr>
# <tr>	<th>	Pierpaolo	Basile	</td>	<th>	Simon	Hengchen	</td>	<th>	Sylvie	Saget	</td>	</tr>
# <tr>	<th>	Barend	Beekhuizen	</td>	<th>	Louise	Holmer	</td>	<th>	Eyal	Sagi	</td>	</tr>
# <tr>	<th>	Meriem	Beloucif	</td>	<th>	Mika	Hämäläinen	</td>	<th>	Asad	Sayeed	</td>	</tr>
# <tr>	<th>	Klaus	Berberich	</td>	<th>	Abhik	Jana	</td>	<th>	Dominik	Schlechtweg	</td>	</tr>
# <tr>	<th>	Aleksandrs	Berdicevskis	</td>	<th>	Péter	Jeszenszky	</td>	<th>	Vidya	Somashekarappa	</td>	</tr>
# <tr>	<th>	Chris	Biemann	</td>	<th>	Dirk	Johannßen	</td>	<th>	Andreas	Spitz	</td>	</tr>
# <tr>	<th>	Damian	Blasi	</td>	<th>	Richard	Johansson	</td>	<th>	Ian	Stewart	</td>	</tr>
# <tr>	<th>	Ricardo	Campos	</td>	<th>	Antti	Kanner	</td>	<th>	Suzanne	Stevenson	</td>	</tr>
# <tr>	<th>	Annalina	Caputo	</td>	<th>	Tom	Kenter	</td>	<th>	Barbro	Wallgren Hemlin	</td>	</tr>
# <tr>	<th>	Brady	Clark	</td>	<th>	Jey Han	Lau	</td>	<th>	Susanne	Vejdemo	</td>	</tr>
# <tr>	<th>	Paul	Cook	</td>	<th>	Liina	Lindström	</td>	<th>	Mikael	Vejdemo Johansson	</td>	</tr>
# <tr>	<th>	Dana	Dannells	</td>	<th>	Behrooz 	Mansouri	</td>	<th>	Melvin	Wevers	</td>	</tr>
# <tr>	<th>	Pavel	Denisov	</td>	<th>	Animesh	Mukherjee	</td>	<th>	Guanghao	You	</td>	</tr>
# <tr>	<th>	Haim	Dubossarsky	</td>	<th>	Luis	Nieto Piña	</td>	<th>	Yihong	Zhang	</td>	</tr>
# </table> 
# </font> -->

<h1 id="programme-committee">Contact</h1>
<a href="mailto:PC-ACLws2019@[remove]languagechange.org" target="_top">Contact us</a> if you have any questions. 

Organisers: 
<a href="https://spraakbanken.gu.se/en/about/staff/nina">Nina Tahmasebi</a>,
<a href="https://adammo12.github.io/adamjatowt/">Adam Jatowt</a>,
<a href="http://www.cs.toronto.edu/~yangxu/">Yang Xu</a>,
<a href="https://spraakbanken.gu.se/en/about/staff/simon">Simon Hengchen</a>,
<a href="https://smontariol.github.io/">Syrielle Montariol</a>, and Haim Dubossarsky. 


<h1>Anti-Harassment Policy</h1>
Our workshop highly values the open exchange of ideas, the freedom of thought and expression, and respectful scientific debate. We support and uphold the <a href="https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy">ACL Anti-Harassment policy</a>, and any workshop participant should feel free to contact any of the workshop organisers or Priscilla Rasmussen, in case of any issues.

<p>References:<br>
 <ul>
<li>Simon Hengchen, Nina Tahmasebi, Dominik Schlechtweg, Haim Dubossarsky.  <a href="https://langsci-press.org/catalog/view/303/3037/2384-1">Challenges for Computational Lexical Semantic Change</a>. Nina Tahmasebi, Lars Borin, Adam Jatowt, Yang Xu, Simon Hengchen (eds). Computational Approaches to Semantic Change. Berlin: Language Science Press.</li>
<li>Nina Tahmasebi, Adam Jatowt, Lars Borin. <a href="https://doi.org/10.5281/zenodo.5040302">Survey of Computational Approaches to Lexical Semantic Change Detection</a>. Nina Tahmasebi, Lars Borin, Adam Jatowt, Yang Xu, Simon Hengchen (eds). Computational Approaches to Semantic Change. Berlin: Language Science Press. </li>
<li>Baayen, R. Harald. 2001. Word Frequency Distributions. Dordrecht: Kluwer Academic Publishers.</li>
<li>Koplenig, Alexander. 2015. The Impact of Lacking Metadata for the Measurement of Cultural and Linguistic Change Using the Google Ngram Data Sets—Reconstructing the Composition of the German Corpus in Times of WWII. Digital Scholarship in the Humanities fqv037. https://doi.org/10.1093/llc/fqv037.</li>
<li>Koplenig, Alexander, Sascha Wolfer & Carolin Müller-Spitzer. 2019. Studying Lexical Dynamics and Language Change via Generalized Entropies: The Problem of Sample Size. Entropy 21(5). https://doi.org/10.3390/e21050464. http://www.mdpi.com/1099-4300/21/5/464.</li>
<li>Labov, William. 1994. Principles of linguistic change (Language in Society 20). Oxford, UK ; Cambridge [Mass.]: Blackwell.</li>
<li>Michel, Jean-Baptiste, Yuan Kui Shen, Aviva Presser Aiden, Adrian Verses, Matthew K. Gray, The Google Books Team, Joseph P. Pickett, et al. 2010. Quantitative Analysis of Culture Using Millions of Digitized Books (Supporting Online Material II). Science 331(14). http://www.sciencemag.org/content/331/6014/176/suppl/DC1 (5 March, 2014).</li>
<li>Pechenick, Eitan Adam, Christopher M. Danforth & Peter Sheridan Dodds. 2015. Characterizing the Google Books Corpus: Strong Limits to Inferences of Socio-Cultural and Linguistic Evolution. (Ed.) Alain Barrat. PLOS ONE 10(10). e0137041. https://doi.org/10.1371/journal.pone.0137041.</li>
<li>Szmrecsanyi, Benedikt. 2016. About text frequencies in historical linguistics: Disentangling environmental and grammatical change. Corpus Linguistics and Linguistic Theory 12(1). 153–171. https://doi.org/10.1515/cllt-2015-0068.</li>
</ul> 




