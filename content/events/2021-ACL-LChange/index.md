+++
title = "2nd International Workshop on Computational Approaches to Historical Language Change 2021 (LChange'21)"
date = 2020-11-09T09:30:00 # Schedule page publish date.
draft = false

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
time_start = 2021-08-05T09:30:00
#time_end = 2030-06-01T15:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Nina Tahmasebi", "Adam Jatowt", "Yang Xu", "Simon Hengchen", "Syrielle Montariol", "Haim Dubossarsky"]

# Abstract and optional shortened version.
#abstract = "
abstract = "In this second LChange workshop, we will bring together the world's pioneers and experts in computational approaches to historical language change with the focus on digital text corpora. In doing so, this workshop carries the triple goals of disseminating the state-of-the-art research on diachronic modelling of language change, fostering international cross-disciplinary collaborations, and exploring the fundamental theoretical and methodological challenges in this growing niche of computational linguistic research."
abstract_short = "Second LChange workshop co-located with ACL2021"

# Name of event and optional event URL.
event = "2nd International Workshop on Computational Approaches to Historical Language Change 2021 (LChange'21)"
#event_url = "https://dh.org.ee/events/dhe2018/"


# Location of event.
location = "Bangkok, Thailand"

# Is this a selected talk? (true/false)
selected = true

# Projects (optional).
#   Associate this talk with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["Language Change Detection", "Historical Semantic Change", "Lexical Replacement", "Digital Humanities"]

# Links (optional).
url_pdf = ""
url_slides = ""
url_video = ""
url_code = ""
#<iframe src="

# Does the content use math formatting?
math = true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]

  # Caption (optional)
  #caption = "Image credit: [**Unsplash**](https://unsplash.com/photos/bzdhc5b3Bxs)"

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Right"
  
   # <p>Natural languages change over time. Every language relies on a finite lexicon to express an infinite set of emerging ideas driven by sociocultural and technological development. This tension is often manifested in the historical emergence of novel word forms and meanings, and the obliteration of existing words and word meanings. Compared to other aspects of language where there are rich formal treatments of change (e.g., phonology, grammar), computational approaches to the time-varying properties of word meanings and forms have just begun to take shape in computational linguistics, natural language processing, and related disciplines.</p>
  # <p>Characterizing the time-varying nature of language will have broad implications and applications in multiple fields including linguistics, artificial intelligence, digital humanities, computational cognitive and social sciences. In this workshop, we will bring together the world's pioneers and experts in <strong>computational approaches to historical language change with the focus on digital text corpora.</strong> In doing so, this workshop carries the triple goals of disseminating the state-of-the-art research on diachronic modelling of language change, fostering international cross-disciplinary collaborations, and exploring the fundamental theoretical and methodological challenges in this growing niche of computational linguistic research.</p>
+++


<p>The workshop builds upon <a href="https://languagechange.org/events/2019-acl-lcworkshop/">its first iteration in 2019</a>,  where we received over <strong>50 submissions</strong> and had over 65 attendees. Just like the first one, the second LChange workshop will be co-located with <a href="https://2021.aclweb.org/">ACL</a> (2021), and, pending on the situation, a hybrid event with possible online participation. We hope to make our second edition another resounding success!</p> 
<p>The call for papers will be similar to last time: all aspects around computational approaches to historical language change with the focus on digital text corpora. If you have published in the field previously, and are inrerested in helping out in the PC to review papers, <a href="mailto:PC-ACLws2019@[remove]languagechange.org" target="_top">send us an email</a>.</p>
<p>We will have two keynote talks, and our first confirmed keynote is  <a href="https://www1.ids-mannheim.de/lexik/personal/koplenig.html">Alexander Koplenig</a> (Leibniz-Institute for the German Language in Mannheim) with the talk <em>Two challenges we face when analyzing diachronic corpora. </em></p>

 <h1>Important Dates</h1>

 <ul>
  <li>April 26, 2021: Paper submission</li>
  <li>May 28, 2021: Notification of acceptance</li>
  <li>June 7, 2021: Camera-ready papers due</li>
  <li>August 5-6, 2021: Workshop date (day will be decided upon later)</li>
</ul> 


 







<h1>Workshop Topics</h1>
<p>Human language changes over time, driven by the dual needs of adapting to ongoing sociocultural and technological development in the world and facilitating efficient communication. In particular, novel words are coined or borrowed from other languages, while obsolete words slide into obscurity. Similarly, words may acquire novel meanings or lose existing meanings. This workshop explores these phenomena by bringing to bear state-of-the-art computational methodologies, theories and digital text resources on exploring the time-varying nature of human language.</p>
<p>Although there exists rich empirical work on language change from historical linguistics, sociolinguistics and cognitive linguistics, computational approaches to the problem of language change <em>particularly how word forms and meanings evolve</em> have only begun to take shape over the past decade or so, with exemplary work on semantic change  and lexical replacement. The motivation has long been related to <em>search</em>, and <em>understanding</em> in diachronic archives. The emergence of long-term and large-scale digital corpora was the prerequisite and has resulted in a slightly different set of problems for this strand of study than have traditionally been studied in historical linguistics. As an example, studies of lexical replacement have largely focused on named entity change (names of e.g., countries and people that change over time) because of the large effect these name changes have for temporal information retrieval.</p>

<p>The aim of this workshop is three-fold. First, within a field that has a lot of challenges (Hengchen et al, 2021) we want to provide pioneering researchers who work on computational methods, evaluation, and large-scale modelling of language change <span><strong>an outlet for disseminating cutting-edge research on topics concerning language change</strong></span>. Currently, researchers in this area have published in a wide range of different venues, from computational linguistics, to cognitive science and digital archiving venues (Tahmasebi et al, 2021). Building on its previous edition, we want to utilize this workshop as a platform for sharing state-of-the-art research progress in this fundamental domain of natural language research.</p>

<p>Second, in doing so we want to <strong>bring together domain experts across disciplines</strong>. We want to connect those that have long worked on language change within historical linguistics and bring with them a large understanding for general linguistic theories of language change; those that have studied change across languages and language families; those that develop and test computational methods for detecting semantic change and laws of semantic change; and those that need knowledge (of the occurrence and shape) of language change, for example, in digital humanities and computational social sciences where text mining is applied to diachronic corpora subject to lexical semantic change.</p>
<p>Third, the detection and modelling of language change using diachronic text and text mining raise <strong>fundamental theoretical and methodological challenges</strong> for future research in this area. The representativeness of text is a first critical issue; works using large diachronic corpora and computational methods for detecting change often claim to find changes that are universally true for a language as a whole. But the jury is out on how results derived from digital literature or newspapers accurately represent changes in language as a whole. We hope to engage corpus linguists, big-data scientists, and computational linguists to address these open issues. Besides these goals, this workshop will also support discussion on the evaluation of computational methodologies for uncovering language change. Verifying change only using positive examples of change often confirms a corpus bias rather than reflecting genuine language change. Larger quantities and higher qualities of text over time result in the detection of more semantic change. In fact, multiple semantic laws have been proposed lately  where later other authors have shown that the detected effects are linked to frequency rather than underlying semantic change . The methodological issue of evaluation, together with good evaluation testsets and standards are of high importance to the research community. We aim to shed some light on these issues and encourage the community to collaborate to find solutions.</p>
<p>The work in semantic change detection <a href="#footnote-1">[1]</a> has, to a large extent, moved to (neural) embedding techniques in recent years . These methods have several drawbacks: the need for very large datasets to produce stable embeddings, and the fact that all semantic information of a word is encoded in a single vector thus limiting the possibility to study word senses separately. A move towards multi-sense embeddings will most likely require even more texts per time unit, which will limit the applicability of these methods to other languages than English and a few others. We want to bring about a discussion on the need for methods that can discriminate and disambiguate among a word's senses (meanings) and that can be used for resource-poor languages with little hope of acquiring the order of magnitude of words needed for creating stable embeddings, possibly using dynamic embeddings that seem to require less text. Finally, knowledge of language change is useful not only on its own, but as a basis for other diachronic textual investigations and in search. </p>

<p>A digital humanities investigation into the living conditions of young women through history cannot rely on the word <em>girl</em> in English, as in the past the reference of <em>girl</em> also included young men. Automatic detecting of language change is useful for many researchers outside of the communities that study the changes themselves and develop methods for their detection. By reaching out to these other communities, we can better understand how to utilize the results for further research and for presenting them to the interested public. In addition, we need good user interfaces and systems for exploring language changes in corpora, for example, to allow for serendipitous discovery of interesting phenomena . In addition to facilitate research on texts, information about language changes is used for measuring document across-time similarity, information retrieval from long-term document archives, the design of OCR algorithms and so on.</p>

<p>We invite original research papers from a wide range of topics, including but not limited to:</p>

 <ul>
  <li> Novel methods for detecting diachronic semantic change and lexical replacement</li>
  <li> Automatic discovery and quantitative evaluation of laws of language change</li>
  <li> Computational theories and generative models of language change</li>
  <li> Sense-aware (semantic) change analysis</li>
  <li> Diachronic word sense disambiguation</li>
  <li> Novel methods for diachronic analysis of low-resource languages</li>
  <li> Novel methods for diachronic linguistic data visualization</li>
  <li> Novel applications and implications of language change detection</li>
  <li> Quantification of sociocultural influences on language change</li>
  <li> Cross-linguistic, phylogenetic, and developmental approaches to language change</li>
  <li> Novel datasets for cross-linguistic and diachronic analyses of language</li>
</ul> 



<h1>Keynote Talks</h1>
Confirmed Speaker:<br>
 <a href="https://www1.ids-mannheim.de/lexik/personal/koplenig.html">Alexander Koplenig</a> (Leibniz-Institute for the German Language in Mannheim) 
<br> Title of talk: <strong>Two challenges we face when analyzing diachronic corpora </strong><br>
Abstract: In my keynote, I want to discuss two important challenges for the quantitative analysis of diachronic corpora that I believe deserve more attention: <br>
<ul> 
<li>	The first challenge is the systematic influence of the sample size when it comes to basically all measures in quantitative linguistics (Baayen 2001). By analysing the lexical dynamics of the German weekly news magazine “Der Spiegel” (consisting of approximately 365,000 articles and 237,000,000 words that were published between 1947 and 2017), I show that this influence makes it difficult to quantify lexical dynamics and language change. I will also demonstrate that standard sampling approaches do not solve this problem. I will suggest an approach that is able to break the sample size dependence but presupposes access to the full text data (Koplenig, Wolfer & Müller-Spitzer 2019). </li>
<li>	The second challenge is of methodological nature and relates to the problem of representativeness of diachronic corpora. Labov (1994) famously stated that "historical documents survive by chance, not by design, and the selection that is available is the product of an unpredictable series of historical accidents." By using both Google Books Ngram data (Michel et al. 2010; Koplenig 2015; Pechenick, Danforth & Dodds 2015) and publicly available data from the German National Bibliography, I will try to show that the problem is even more fundamental, because there is good reason to believe that composition of the body of published written works (from which a corresponding corpus is supposed to be sampled from) systematically changes as a function of time. This makes it difficult to disentangle actual language change from environmental changes in the textual habitat  (Szmrecsanyi 2016).</li>
</ul> 

<!--<br>
<a href="http://people.ds.cam.ac.uk/hd423/">Haim Dubossarsky</a> (Research Fellow at University of Cambridge) <br>
Title of talk: [Semantic change in the time of Machine Learning, doing it right!](/pdf/lchange19/lchange_Dubossarsky.pdf)<br>
-->



<!--TODO_EDIT-->
<h1>Submissions</h1>
<p>We accept three types of submissions, long papers, short papers and abstracts, following the ACL2021 style, and the <a href="https://www.aclweb.org/adminwiki/index.php?title=ACL_Policies_for_Submission,_Review_and_Citation">ACL submission policy</a>.</p>
<!-- 
 <p>Long papers may consist of up to eight (8) pages of content, plus unlimited references, short papers may consist of up to four (4) pages of content; final versions will be given one additional page of content so that reviewers' comments can be taken into account. Abstracts may consist of up to two (2) pages of content, plus unlimited references. </p>
 <p>Submissions should be sent in electronic forms, using the Softconf START conference management system. The <a href="https://www.softconf.com/acl2019/lcworkshop/">submission site</a> is now available.  </p>
-->
<p>Details on paper length and submission proceedure will be posted once released by ACL2021. 

<p>The workshop is planned to last a full day. Submissions are open to all, and are to be submitted anonymously. All papers will be refereed through a double-blind peer review process by at least three reviewers with final acceptance decisions made by the workshop organizers.</p>


<!-- # <h1 id="programme-committee">Programme Committee</h1>
# <font size="30" >
# <table style="font-size: 14px"> 
# <tr>	<th>	Nicholas	A.Lester 	</td>	<th>	Stian Rødven	Eide	</td>	<th>	Bill	Noble	</td>	</tr>
# <tr>	<th>	Yvonne	Adesam	</td>	<th>	Antske	Fokkens	</td>	<th>	Kjetil	Norvag	</td>	</tr>
# <tr>	<th>	Rami	Aly	</td>	<th>	Mats	Fridlund	</td>	<th>	Ella	Rabinovich	</td>	</tr>
# <tr>	<th>	Avishek	Anand	</td>	<th>	Michael	Färber	</td>	<th>	Taraka	Rama	</td>	</tr>
# <tr>	<th>	Timothy	Baldwin	</td>	<th>	Johannes	Hellrich	</td>	<th>	Jacobo	Rouces	</td>	</tr>
# <tr>	<th>	Pierpaolo	Basile	</td>	<th>	Simon	Hengchen	</td>	<th>	Sylvie	Saget	</td>	</tr>
# <tr>	<th>	Barend	Beekhuizen	</td>	<th>	Louise	Holmer	</td>	<th>	Eyal	Sagi	</td>	</tr>
# <tr>	<th>	Meriem	Beloucif	</td>	<th>	Mika	Hämäläinen	</td>	<th>	Asad	Sayeed	</td>	</tr>
# <tr>	<th>	Klaus	Berberich	</td>	<th>	Abhik	Jana	</td>	<th>	Dominik	Schlechtweg	</td>	</tr>
# <tr>	<th>	Aleksandrs	Berdicevskis	</td>	<th>	Péter	Jeszenszky	</td>	<th>	Vidya	Somashekarappa	</td>	</tr>
# <tr>	<th>	Chris	Biemann	</td>	<th>	Dirk	Johannßen	</td>	<th>	Andreas	Spitz	</td>	</tr>
# <tr>	<th>	Damian	Blasi	</td>	<th>	Richard	Johansson	</td>	<th>	Ian	Stewart	</td>	</tr>
# <tr>	<th>	Ricardo	Campos	</td>	<th>	Antti	Kanner	</td>	<th>	Suzanne	Stevenson	</td>	</tr>
# <tr>	<th>	Annalina	Caputo	</td>	<th>	Tom	Kenter	</td>	<th>	Barbro	Wallgren Hemlin	</td>	</tr>
# <tr>	<th>	Brady	Clark	</td>	<th>	Jey Han	Lau	</td>	<th>	Susanne	Vejdemo	</td>	</tr>
# <tr>	<th>	Paul	Cook	</td>	<th>	Liina	Lindström	</td>	<th>	Mikael	Vejdemo Johansson	</td>	</tr>
# <tr>	<th>	Dana	Dannells	</td>	<th>	Behrooz 	Mansouri	</td>	<th>	Melvin	Wevers	</td>	</tr>
# <tr>	<th>	Pavel	Denisov	</td>	<th>	Animesh	Mukherjee	</td>	<th>	Guanghao	You	</td>	</tr>
# <tr>	<th>	Haim	Dubossarsky	</td>	<th>	Luis	Nieto Piña	</td>	<th>	Yihong	Zhang	</td>	</tr>
# </table> 
# </font> -->

<h1 id="programme-committee">Contact</h1>
<a href="mailto:PC-ACLws2019@[remove]languagechange.org" target="_top">Contact us</a> if you have any questions. 

Organisers: 
<a href="https://spraakbanken.gu.se/en/about/staff/nina">Nina Tahmasebi</a>,
<a href="https://adammo12.github.io/adamjatowt/">Adam Jatowt</a>,
<a href="http://www.cs.toronto.edu/~yangxu/">Yang Xu</a>,
<a href="https://spraakbanken.gu.se/en/about/staff/simon">Simon Hengchen</a>,
<a href="https://smontariol.github.io/">Syrielle Montariol</a>, and Haim Dubossarsky. 


<h1>Anti-Harassment Policy</h1>
Our workshop highly values the open exchange of ideas, the freedom of thought and expression, and respectful scientific debate. We support and uphold the <a href="https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy">ACL Anti-Harassment policy</a>, and any workshop participant should feel free to contact any of the workshop organisers or Priscilla Rasmussen, in case of any issues.

<p>References:<br>
 <ul>
<li>Simon Hengchen, Nina Tahmasebi, Dominik Schlechtweg, Haim Dubossarsky. Challenges for Computational Lexical Semantic Change. To appear in: Nina Tahmasebi, Lars Borin, Adam Jatowt, Yang Xu, Simon Hengchen (eds). Computational Approaches to Semantic Change. Berlin: Language Science Press.</li>
<li>Nina Tahmasebi, Adam Jatowt, Lars Borin. <a href="https://arxiv.org/abs/1811.06278">Survey of Computational Approaches to Lexical Semantic Change Detection</a>. To appear in: Nina Tahmasebi, Lars Borin, Adam Jatowt, Yang Xu, Simon Hengchen (eds). Computational Approaches to Semantic Change. Berlin: Language Science Press. </li>
<li>Baayen, R. Harald. 2001. Word Frequency Distributions. Dordrecht: Kluwer Academic Publishers.</li>
<li>Koplenig, Alexander. 2015. The Impact of Lacking Metadata for the Measurement of Cultural and Linguistic Change Using the Google Ngram Data Sets—Reconstructing the Composition of the German Corpus in Times of WWII. Digital Scholarship in the Humanities fqv037. https://doi.org/10.1093/llc/fqv037.</li>
<li>Koplenig, Alexander, Sascha Wolfer & Carolin Müller-Spitzer. 2019. Studying Lexical Dynamics and Language Change via Generalized Entropies: The Problem of Sample Size. Entropy 21(5). https://doi.org/10.3390/e21050464. http://www.mdpi.com/1099-4300/21/5/464.</li>
<li>Labov, William. 1994. Principles of linguistic change (Language in Society 20). Oxford, UK ; Cambridge [Mass.]: Blackwell.</li>
<li>Michel, Jean-Baptiste, Yuan Kui Shen, Aviva Presser Aiden, Adrian Verses, Matthew K. Gray, The Google Books Team, Joseph P. Pickett, et al. 2010. Quantitative Analysis of Culture Using Millions of Digitized Books (Supporting Online Material II). Science 331(14). http://www.sciencemag.org/content/331/6014/176/suppl/DC1 (5 March, 2014).</li>
<li>Pechenick, Eitan Adam, Christopher M. Danforth & Peter Sheridan Dodds. 2015. Characterizing the Google Books Corpus: Strong Limits to Inferences of Socio-Cultural and Linguistic Evolution. (Ed.) Alain Barrat. PLOS ONE 10(10). e0137041. https://doi.org/10.1371/journal.pone.0137041.</li>
<li>Szmrecsanyi, Benedikt. 2016. About text frequencies in historical linguistics: Disentangling environmental and grammatical change. Corpus Linguistics and Linguistic Theory 12(1). 153–171. https://doi.org/10.1515/cllt-2015-0068.</li>
</ul> 



<p id="footnote-1">[1] Often, the work from the computational community has a wider take on semantic change than traditional historical linguistics, for example, with novel words and senses as well as change to the senses themselves as a part.</p>


